---
title: "UBC Science Specialization Data"
output: html_document
---

## Personal Project - UBC Science Specializations Analysis

## Author
* Calvin Du (calvingdu@gmail.com)

# Part 1: Loading and Cleaning up Data 

In this project, I'll be looking at the UBC Science Specializations Spreadsheet as provided by a FOI request to UBC. I'll be exploring the data in various ways, such as how requirements have changed throughoug the years and if COVID was a factor in that. 

To begin, I first load the data and clean it up to allow for consistency and to remove any errors. 

```{r}
library(tidyverse)
library(haven)

specialization_data <- read_csv("SPECIALIZATION_DATA.csv")
# remove variables: Space, Initial Admit Number, Inital Reject Number (irrevelevant to analysis) & change column names 
spec_data <- specialization_data[,-c(4,5,6,7)]
colnames(spec_data) <- c("Year","Option","Spec","Max Grade","Min Grade")

# remove rows that have no specialization or have no min grade
spec_data <- filter(spec_data, !is.na(spec_data$Spec) & !is.na(spec_data$`Min Grade`))
spec_data <- filter(spec_data, !spec_data$`Min Grade`== 0)

# Turn Max and Min Grade from chr to dbl
spec_data$'Min Grade' <- as.numeric(spec_data$'Min Grade')
spec_data$'Max Grade' <- as.numeric(spec_data$'Max Grade')

# Ensure max grade > min grade to make sure there is no data entry errors 
#filter(spec_data, (spec_data$`Min Grade` > spec_data$`Max Grade`)) # found biotech in 2020 min was 89.25 while max for 73.96 so I switch them <- Test  
spec_data$`Min Grade`[(spec_data$Year == 2020) & (spec_data$Spec == "Honours (1136): Biotechnology")] <- 73.96
spec_data$`Max Grade`[(spec_data$Year == 2020) & (spec_data$Spec == "Honours (1136): Biotechnology")] <- 89.25
# filter(spec_data, (spec_data$Year == 2020) & (spec_data$Spec == "Honours (1136): Biotechnology")) # <- Test

# Found that CPSC (Excluding CPSC Major Domestic Student) & CPSC (Excluding Domestic Student) are the same thing but different names --> I also change the names to make more sense
spec_data$Option[(spec_data$Option == 'CPSC (Excluding CPSC Major Domestic Student)')] <- 'CPSC (Excluding Domestic Student)'

spec_data$Option[(spec_data$Option == 'CPSC (Excluding Domestic Student)')]       <- 'CPSC (International)'
spec_data$Option[(spec_data$Option == 'CPSC (Excluding International Students)')] <- 'CPSC (Domestic)'

# Found that 'Honours (1093): Biophysics (BIOP)' option switches from Honours to Combined Honours in 2020, I switch it to Honours for consistency 
spec_data$Option[((spec_data$Year == 2020) | (spec_data$Year == 2021)) & (spec_data$Spec == 'Honours (1093): Biophysics (BIOP)')] <- 'Honours'
#filter(spec_data, spec_data$Spec == 'Honours (1093): Biophysics (BIOP)') # <- Test  

# Same with The Options: Combined Majors & Combined Major
spec_data$Option[(spec_data$Option == 'Combined Majors')] <- 'Combined Major'

print(spec_data)
```

In 2018, I found CPSC splits from general seats to having seperate seats and therefore admission requirements for domestic and international students. Because of this in a lot of my analysis, I'll be combining the two together as an aggregate in order to have a consistent measure of CPSC specialization requirements. The following code block is utilized throughout all the parts to make use of this aggregate.

```{r Aggregating Comp Sci}
# this code box is nesessary
CPSC_Data = filter(spec_data, spec_data$Option == 'CPSC' | spec_data$Option == 'CPSC (Domestic)' | spec_data$Option == 'CPSC (International)')
CPSC_Data

CPSC_Min <- CPSC_Data %>%
            group_by(Year) %>%
            summarize(
              Option = 'CPSC', 
              Spec = 'CPSC',
              `Max Grade` = mean(`Max Grade`),
              `Min Grade` = mean(`Min Grade`),
            ) 

#Use Interpolation to estimate 2018 min grade as there is no data on domestic min grade 
CPSC_2018_mean <- mean(c((CPSC_Min$`Min Grade`[CPSC_Min$Year == 2017]),(CPSC_Min$`Min Grade`[CPSC_Min$Year == 2019])))

CPSC_Min$`Min Grade`[CPSC_Min$Year == 2018] <- CPSC_2018_mean

CPSC_Min
```


# Part 2: Looking at individual Options (Average of Everything, CPSC, HONOURS, Integrated Science (specific major known for being premed))

The following code blocks can be used for initial exploration on how the avg_min for certain "options" of specializations have changed from 2015 - 2021. These options are from UBC's data itself to categorize specializations in terms of honours, major, CPSC, etc. 

```{r Summarize - All Majors}
Yearly_Min <- spec_data %>%
            group_by(Year) %>%
            summarize(
                avg_min = mean(`Min Grade`),
                avg_max = mean(`Max Grade`)
            )

Yearly_Min
```

```{r Summarize - Honours}
Honours_data <- filter(spec_data, spec_data$Option == 'Honours')
Honours_min <- Honours_data %>% 
  group_by(Year) %>% 
  summarize(
    avg_min = mean(`Min Grade`),
    avg_max = mean(`Max Grade`)
  )

Honours_min
```

```{r Summarize - Integrated Science}
integrated_data <- filter(spec_data, spec_data$Spec== 'Major (1682): Integrated Sciences (INSC)')
integrated_data
integrated_min <- integrated_data %>% 
  group_by(Year) %>% 
  summarize(
    avg_min = mean(`Min Grade`),
    avg_max = mean(`Max Grade`)
  )

integrated_min
```

# Part 3: Looking at Relationships & Visual Plots

I first begin by creating a plot that showcases the relationship between different 'Options' (that is defined by UBC) and how their minimum requirements change throughout the years 

I'll first work the data in order to let it work in my visualization

```{r Pre-emptive Cleaning up of data}
# CPSC splits into Domestic & International in 2018, so for the sake of consistency I make a new Option that combines them 
spec_options_data <- spec_data 

spec_options_data <- rbind(spec_options_data, CPSC_Min)
spec_options_data <- arrange(spec_options_data, Year, Option)
spec_options_data <- filter(spec_options_data, !(spec_options_data$Option == 'CPSC (International)' & spec_options_data$Year == 2018)) #Consistent with Domestic that starts at 2019


# I get rid of certain options that only befit one type of major (except CPSC) to avoid clutter 
spec_options_data <- filter(spec_options_data, !spec_options_data$Option == 'COGS')
spec_options_data <- filter(spec_options_data, !spec_options_data$Option == 'STAT')

```

Then I make the visualization, noting that CPSC Domestic & International start at 2019 and the CPSC category after 2018 is an average of the two 

```{r Plot of UBC Options Requirements}
options_data <- spec_options_data %>%
  group_by(Option, Year) %>%
  summarize(
    avg_min = mean(`Min Grade`),
    avg_max = mean(`Max Grade`))
  
  options_data
  
  plot <- ggplot(data = options_data,
  aes(
  x = Year,
  y = avg_min,
  color = Option,
  fill = Option
  ))
  
  
  plot <- plot + labs(
  x = "Year",
  y = "Grade Requirement",
  color = "Degree Category",
  fill = "Degree Category",
  title = "Grade Requirement over Time"
  )
  
  plot <- plot + scale_color_brewer(palette ="Dark2")
    
  plot1 <- plot + geom_line()
  plot1
```

# Part 3b: Looking at Grade Requirements for Custom Categories 

In the following plot, instead of using UBC's 'options' to aggregate specializations, I instead use my own categories in which I believe can provide a better representation of the data. The categories I choose are: Life Sciences, Numerical Sciences, Computer Science (it's own specialization), Specializations considered competetive in 2021 (have a requirement of 75+) and an aggregate of all the specializations

```{r Custom Categories & Requirements}
#This function creates a subset of spec_data based on the list of specializations given 
list_spec <- function(speclist) {
  listofspec <- c() #gives me an empty subset 
  
  for (val in speclist) {
    specific_subset <- subset(spec_data, Spec == val)
    listofspec <- rbind(listofspec, specific_subset)
  }
  return(listofspec)
}

#This lists is determined by how UBC defines programs on their website (https://you.ubc.ca/programs/#mode=by-topic&viewMode=list) 
lifesciences <- c('Major (3502): Behavioural Neuroscience (PSYC)', 'Major (0244): Biochemistry (BIOC)', 'Major (3095): Biology (BIOL)', 'Major (1682): Integrated Sciences (INSC)', 'Major (1153): Microbiology and Immunology (MBIM)', 'Major (0311): Pharmacology (PCTH)', 'Honours (1136): Biotechnology', 'Honours (3221): Cellular, Anatomical and Physiological Sciences (CAPS)', 'Combined Honours (3508): Biochemistry and Forensic Science', 'Honours (1093): Biophysics (BIOP)')

#This list is what I consider numerical sciences (Note: I use the average of International and Domestic CPSC after the specialization splits in 2018)
numericalsciences <- c('Major (0562): Statistics (STAT)', 'Major Cognitive Systems(1225): Cognition and Brain', 'Major Cognitive Systems(1226): Computational Intelligence and Design', 'Major (0456): Mathematics (MATH)', 'Major (0524) Physics (PHYS)', 'Honours (0166): Mathematics (MATH)', 'Honours (0344): Physics (PHYS)', 'Combined Honours (0009): Physics and Astronomy (PHYS, ASTR)', 'Combined Honours (0014): Physics and Mathematics (PHYS, MATH)') 

#Assigning Categories to each subset 
categorized_data_lifesciences <- list_spec(lifesciences) %>%
  mutate(Category = 'Life Sciences') %>% 
        as_factor()

categorized_data_numericalsciences <- rbind((list_spec(numericalsciences)),CPSC_Min) %>%
  mutate(Category = 'Numerical Sciences') %>% 
        as_factor()

categorized_data_compsci <- CPSC_Min %>%
  mutate(Category = 'Computer Science') %>% 
        as_factor()

#Competetive Specializations does not include Comp Sci --> This a list of specializations that have a requirement >75 in 2021 
spec_data_comp_2021 <- filter(spec_data, (spec_data$Year == 2021) & (spec_data$`Min Grade` > 75) & !spec_data$Option == 'CPSC (Domestic)' & !spec_data$Option == "CPSC (International)")
list_spec_comp <- c(t(spec_data_comp_2021$Spec))

categorized_data_comp <- list_spec(list_spec_comp) %>%
      mutate(Category = 'Comp Specializations (Not Comp Sci)') %>% 
      as_factor()


categorized_data_everything <- spec_data %>%
    mutate(Category = 'All Specializations') %>% 
      as_factor()
  
categorized_data <- rbind(categorized_data_lifesciences, categorized_data_numericalsciences, categorized_data_compsci, categorized_data_comp, categorized_data_everything)

categorized_data

#Plot 
categorized_data_plot <- categorized_data %>%
  group_by(Category, Year) %>%
  summarize(
    avg_min = mean(`Min Grade`),
    avg_max = mean(`Max Grade`))
  
  categorized_data_plot
  
  plot <- ggplot(data = categorized_data_plot,
  aes(
  x = Year,
  y = avg_min,
  color = Category,
  fill = Category,
  label = Category
  ))
  
  
  plot <- plot + labs(
  x = "Year",
  y = "Grade Requirement",
  color = "Degree Category",
  fill = "Degree Category",
  title = "Grade Requirement over Time"
  )
  
  plot <- plot + scale_color_brewer(palette ="Dark2")
    
  categorized_plot <- plot + geom_line()
  categorized_plot

```

The plot definetely shows that specializations have requirements rising throughout the years, in particular in 2020 and 2021 which are referred as te COVID years. Something to note though is that scale of the plot is only in 5% intervals in which most of the changes are within. These are not crazy changes and therefore cannot be conclusive on their own. In the following part, I'll use statistics to determine how probable this situation would've been following the trends in 2015-2019. 

# Part 4: Actual Statistics to see if COVID affected requirements
Using the data made in Part 3b (categorized_data) which is the data on requirement averages of the various categories I made, I will go on to use linear regression in order to extrapolate and forecast what 2020 & 2021 would be with the trends present in 2015-2019 and use that to compare with the actual 2020 & 2021 averages that were affected by COVID. 

```{r Regression Plots of Categorized Data}
#This function makes a regression plot of a categorized dataset
make_regression_plot <- function(categorized_dataset) {
catagorized_dataset_plot_data <- categorized_dataset %>%
  group_by(Category, Year) %>%
  summarize(
    avg_min = mean(`Min Grade`),
    avg_max = mean(`Max Grade`))

plot <- ggplot(data = catagorized_dataset_plot_data,
aes(
  x = Year,
  y = avg_min,
  color = Category,
  fill = Category
  ))
  
  
plot <- plot + labs(
  x = "Year",
  y = "Grade Requirement",
  color = "Degree Category",
  fill = "Degree Category",
  title = "Grade Requirement over Time"
  )
  
plot <- plot + scale_color_brewer(palette ="Dark2")

reg <- lm(avg_min~Year, filter(catagorized_dataset_plot_data, (!catagorized_dataset_plot_data$Year == 2020 & !catagorized_dataset_plot_data$Year == 2021))) # filtering here makes the regression line not include 2020 & 2021
coeff <- coefficients(reg)

intercept <- coeff[1]
slope <- coeff[2]

categorized_plot <- plot + geom_point() + geom_abline(slope = slope, intercept = intercept) + ylim(60,85)
return (categorized_plot)
}

categorized_datasets <- list(categorized_data_lifesciences, categorized_data_numericalsciences, categorized_data_comp, categorized_data_compsci, categorized_data_everything)

regression_plots <- lapply(categorized_datasets, make_regression_plot)
regression_plots
```

After seeing the regression plots, it can be seen that the 2020 & 2021 requirements do seem to generally fit in with the projected means. I can further dive into this using a t-test involving all the categories except comp sci (because there is not enough observations) by analyzing if the actual mean in 2021 is probable with 95% confidence to the projected 2021 mean that is derived from the regression analysis from the previous part. 

```{r T-Tests of Categorized Data}

categorized_datasets <- list(categorized_data_lifesciences, categorized_data_numericalsciences, categorized_data_comp, categorized_data_everything)

#This function takes in a dataset and does a t-test to evaluate the acutal 2021 requirement mean in comparison to the projected mean from the regression line that extrapolates from data in 2015 - 2019
t_test_function <- function(catagorized_dataset) {
categorized_dataset <- catagorized_dataset

catagorized_dataset_plot_data <- categorized_dataset %>%
  group_by(Category, Year) %>%
  summarize(
    avg_min = mean(`Min Grade`),
    sd_min = sd(`Min Grade`),
    avg_max = mean(`Max Grade`))
  
filtered_data <- filter(catagorized_dataset_plot_data, (!catagorized_dataset_plot_data$Year == 2020 & !catagorized_dataset_plot_data$Year == 2021))

reg <- lm(avg_min~Year, filtered_data)
coeff <- coefficients(reg)

intercept <- coeff[1]
slope <- coeff[2]

projected2021 <- intercept + slope*2021

actual2021 <- catagorized_dataset_plot_data$`avg_min`[catagorized_dataset_plot_data$Year == 2021]
actualSD2021 <- catagorized_dataset_plot_data$`sd_min`[catagorized_dataset_plot_data$Year == 2021]

# Hypothesis Test done by hand
# test <- pnorm(projected2021, actual2021, actualSD2021)
# test


# Confidence Intervals done by hand
# number_of_rows <-  categorized_dataset %>%
#   group_by(Spec) %>%
#   summarize() %>% 
#   nrow()
#   
#   
# standarderror <- actualSD2021 / sqrt(number_of_rows)
# criticalvalue <- qt(((1-0.95)/2), 9)
# 
# confidenceintervals <-- c((actual2021-(criticalvalue*-1)*standarderror)*-1, (actual2021+(criticalvalue*-1)*standarderror)*-1)
# 
# confidenceintervals

filtered <- filter(categorized_dataset, categorized_dataset$Year == 2021)$`Min Grade`
filtered

t <- t.test(
      filtered,
       alternative = "two.sided",
       mu = projected2021,
       conf.level = 0.95)

return (t)
}

t_tests <- lapply(categorized_datasets, t_test_function)
t_tests
```

All of these t-tests demonstrate that with a significance value of 95%, all of actual means are within the confidence interval. We can therefore accept the null hypothesis that the mean is = to the projected mean and therefore conclude that COVID did not impact the specialization requirements in Science for the year 2021.

# Part 5: Alternative View: Looking at how "Competetive" UBC Specializations are getting by count 

The following plot will demonstrate how many specializations have requirements above a certain cutoff. By viewing how this count changes throughout the years, it can be seen how competeteive specializations are getting.  

```{r Count of Specializations > Cutoff Plot}
#This function takes in a cutoff and provides a table of how many specializations per year have a min grade above that cutoff 
count_spec_with_cutoff <- function(cutoff) {
  comp_spec_data <- spec_data %>% 
    mutate(Competetive = case_when( 
        (`Min Grade` > cutoff) ~ "Competetive",
        TRUE ~ "Uncompetetive")) %>% 
        as_factor()
  
    comp_spec_data <- filter(comp_spec_data, comp_spec_data$Competetive == "Competetive")
    count_table <- comp_spec_data %>%
    group_by(Year) %>%
    summarize( 
    'Count' = n(),
    Cutoff = cutoff)
    count_table$Cutoff <- as.character(count_table$Cutoff)
    
return (count_table)
}

count_data <- rbind(count_spec_with_cutoff(65), count_spec_with_cutoff(70), count_spec_with_cutoff(75), count_spec_with_cutoff(80), count_spec_with_cutoff(85))
count_data

count_plot <- ggplot(count_data,
                       aes(
                         x = Year,
                         y = Count,
                         color = Cutoff,
                         fill = Cutoff
                       ))

count_plot <- count_plot + labs(
  x = "Year",
  y = "Amount of Specializations",
  color = "Cutoff",
  fill = "Cutoff",
  title = "Amount of Specializations Over a Cutoff"
  )
    
  count_plot <- count_plot + geom_col(position = "dodge")
  
  count_plot
```

While this plot does give data that showcases how specializations are having higher cutoffs over time, it may be more representative to show how much they are changing from their baseline (2015) in order to give a better view on the change in count rather than total count

```{r Difference in Count from 2015}
#This function takes in a cutoff and provides a table of how many specializations per year have this requirement more there is than in 2015 
count_diff_with_cutoff <- function(cutoff) {
 count_table <- count_spec_with_cutoff(cutoff)
 diff_table <- count_table %>%
  mutate(Difference = Count - count_table$Count[Year == 2015]) %>%
  filter(!count_table$Year == 2015)
  
return (diff_table)
}

diff_data <- rbind(count_diff_with_cutoff(65), count_diff_with_cutoff(70), count_diff_with_cutoff(75), count_diff_with_cutoff(80), count_diff_with_cutoff(85))

diff_data

diff_plot <- ggplot(diff_data,
                       aes(
                         x = Year,
                         y = Difference,
                         color = Cutoff,
                         fill = Cutoff
                       ))

diff_plot <- diff_plot + labs(
  x = "Year",
  y = "Difference in Count from 2015",
  color = "Cutoff",
  fill = "Cutoff",
  title = "Difference in Amount of Specializations Over a Cutoff from 2015"
  )
    
  diff_plot <- diff_plot + geom_col(position = "dodge")
  
  diff_plot
```

It's found that the amount of specializations that have a requirement of above 75 or 80 is significant especially in 2020 and 2021. This can demonstrate that specializations are getting more competetive with time and may be affected by COVID as 2020 & 2021 where the specializaiton years were affected by COVID.

# Part 5b - Looking at Competetetive Specializations but with Consistent Specializations

Though the plots in part 5 demonstrate a change in amount, it does not account for the fact that UBC adds/removes majors throughout the years that can affect count. Therefore, in the following analysis, I will only look at specializations that are present throughout 2015 - 2021 consistently in the following plots. Due to CPSC being split in 2018, I'll also be using the average of domestic/international

```{r Creating Consistent Data}
spec_data_cpsc_consistent <- filter(spec_data, (!spec_data$Option == 'CPSC (International)' & !spec_data$Option == 'CPSC (Domestic)' & !spec_data$Option == 'CPSC'))
spec_data_cpsc_consistent <- rbind(spec_data_cpsc_consistent, CPSC_Min)
spec_data_consistent <- spec_data_cpsc_consistent %>%
  group_by(Spec) %>%
  filter(all(2015:2021 %in% Year))

spec_data_consistent

#This is a test to verify that the specializations are consistent throughout the years
count_spec_data <- spec_data_consistent %>%
    group_by(Year) %>%
    summarise(Count = n())
    
count_spec_data
```

```{r Specialization Count Above Cutoff (Consistent)}
count_spec_with_cutoff_consistent <- function(cutoff) {
  comp_spec_data_consistent <- spec_data_consistent %>% 
    mutate(Competetive = case_when( 
        (`Min Grade` > cutoff) ~ "Competetive",
        TRUE ~ "Uncompetetive")) %>% 
        as_factor()
  
     comp_spec_data_consistent <- comp_spec_data_consistent %>%
       ungroup %>%
       filter(comp_spec_data_consistent$Competetive == "Competetive")
     
    count_table_consistent <- comp_spec_data_consistent %>%
    group_by(Year) %>%
    summarize( 
    'Count' = n(),
    Cutoff = cutoff)
    count_table_consistent$Cutoff <- as.character(count_table_consistent$Cutoff)
    
return (count_table_consistent)
}

count_data_consistent <- rbind(count_spec_with_cutoff_consistent(65), count_spec_with_cutoff_consistent(70), count_spec_with_cutoff_consistent(75), count_spec_with_cutoff_consistent(80), count_spec_with_cutoff_consistent(85))
# to test if this is actually consistent, put cutoff at 0 and add it onto data
count_data_consistent

count_plot_consistent <- ggplot(count_data_consistent,
                       aes(
                         x = Year,
                         y = Count,
                         color = Cutoff,
                         fill = Cutoff
                       ))

count_plot_consistent <- count_plot_consistent + labs(
  x = "Year",
  y = "Amount of Specializations",
  color = "Cutoff",
  fill = "Cutoff",
  title = "Amount of Specializations Over a Cutoff (Consistent)"
  )
    
  count_plot_consistent <- count_plot_consistent + geom_col(position = "dodge")
  
  count_plot_consistent
```

And for difference in count again:

```{r Specialization Count Difference from 2015 (Consistent)}
count_diff_with_cutoff_consistent <- function(cutoff) {
 count_table_consistent <- count_spec_with_cutoff_consistent(cutoff)
 diff_table <- count_table_consistent %>%
  mutate(Difference = Count - count_table_consistent$Count[Year == 2015]) %>%
  filter(!count_table_consistent$Year == 2015)
  
return (diff_table)
}

diff_data_consistent <- rbind(count_diff_with_cutoff_consistent(65), count_diff_with_cutoff_consistent(70), count_diff_with_cutoff_consistent(75), count_diff_with_cutoff_consistent(80), count_diff_with_cutoff_consistent(85))

diff_data_consistent

diff_plot_consistent <- ggplot(diff_data_consistent,
                       aes(
                         x = Year,
                         y = Difference,
                         color = Cutoff,
                         fill = Cutoff
                       ))

diff_plot_consistent <- diff_plot_consistent + labs(
  x = "Year",
  y = "Difference in Count from 2015",
  color = "Cutoff",
  fill = "Cutoff",
  title = "Difference in Amount of Specializations Over a Cutoff from 2015 (Consistent)"
  )
    
  diff_plot_consistent <- diff_plot_consistent + geom_col(position = "dodge")
  
  diff_plot_consistent
```

I can see the difference this makes by comparing the plots side by side

```{r Graphs side by side}
count_plot + ylim(0,40)
count_plot_consistent + ylim(0,40)
diff_plot + ylim(-5,25)
diff_plot_consistent + ylim(-5,25)
```

We can see that throughout the years, there are not dramatic spikes in the change with the biggest being in 2019 and 2020 that occur in the cutoff of 75. The following code block allows us to find which specializations it is that had this requirement change that goes beyond the cutoff. For example, if I were to put 2018 as a lower year and 2019 as an upper year with the cutoff at 75, I could see which specializations had a requirement cutoff below 75 in 2018 and above 75 in 2019. 

```{r Making Function to Find Specializations with Dramatic Change} 
#This function takes in 2 years and returns a table of specializations that in the lower year, had a requirement lower than the cutoff but in the upperyear had a requirement above the cutoff 
specialization_requirement_change <- function(loweryear, upperyear, cutoff) {

spec_data_consistent_part4 <- spec_data %>%
  group_by(Spec) %>%
  filter(all(loweryear:upperyear %in% Year))

spec_data_consistent_part4

summarise_spec_spec_data <- spec_data_consistent_part4 %>%
  group_by(Spec) %>%
  summarise()

summarise_spec_spec_data

list_spec_data <- c(t(summarise_spec_spec_data$Spec))

list_spec_data <- list_spec_data
list_spec_data

empty_list_spec <- c()
for (variable in list_spec_data) {
  lowerrequirement <- spec_data$`Min Grade`[(spec_data$Year == loweryear) & (spec_data$Spec == variable)]
  upperrequirement <- spec_data$`Min Grade`[(spec_data$Year == upperyear) & (spec_data$Spec == variable)]
  requirement <- (lowerrequirement < cutoff & cutoff <= upperrequirement)
  
  if(requirement) {
    specific_subset <- subset(spec_data, ((spec_data$Spec == variable) & ((spec_data$Year == loweryear) | (spec_data$Year == upperyear))))
    empty_list_spec <- rbind(empty_list_spec, specific_subset)
  }
}

return (empty_list_spec)
}
```

In particular, a relatively spike can be found between 2018 and 2019 in that there is a large count difference for majors with a requriement > 75. By using this tool I can isolate 5 majors that showcase this change and using the tool in the reverse order, can find 2 specializations that show the reverse

```{r}
specialization_requirement_change(2015, 2019, 75)
specialization_requirement_change(2019, 2018, 75)
```

While this does not implicate any correlation towards COVID, it is interesting to see which specializations are drastically changing through the years. 

#Part 5c: Interactive Code! 

This function takes in 2 years and returns a table of specializations that in the first year, had a requirement lower than the cutoff but in the second year had a requirement above the cutoff 

```{r}
specialization_requirement_change(2019, 2021, 79)
```




